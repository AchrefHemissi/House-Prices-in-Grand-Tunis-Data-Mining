{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1aa894",
   "metadata": {},
   "source": [
    "## 1. Advanced Data Engineering\n",
    "\n",
    "We implement a dynamic cleaning pipeline that adapts to the distribution of each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b30dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../data/processed/merged.csv')\n",
    "df['city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7604357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dca9a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.1 Structural Cleaning ---\n",
    "for col in ['city', 'region']:\n",
    "    df[col] = df[col].astype(str).str.strip()\n",
    "    df[col] = df[col].astype(str).str.lower()\n",
    "\n",
    "print(\"Unique cities:\", df['city'].unique())\n",
    "# Handle numeric missing values\n",
    "num_cols = ['room_count', 'bathroom_count', 'size']\n",
    "df[num_cols] = df[num_cols].replace(-1, np.nan)\n",
    "\n",
    "# Scope Filter\n",
    "df = df[\n",
    "    (df['city'].isin(['tunis', 'ariana', 'ben arous', 'la manouba']))\n",
    "].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e51fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.3 Statistical Outlier Removal (IQR Method) ---\n",
    "# We derive 'price_per_m2' to detect anomalies relative to size.\n",
    "df['price_per_m2'] = df['price'] / df['size']\n",
    "\n",
    "def remove_outliers_iqr(group):\n",
    "    Q1 = group['price_per_m2'].quantile(0.25)\n",
    "    Q3 = group['price_per_m2'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return group[(group['price_per_m2'] >= lower_bound) &\n",
    "                 (group['price_per_m2'] <= upper_bound)]\n",
    "\n",
    "print(f\"Entries before IQR cleaning: {len(df)}\")\n",
    "# Apply IQR filtering per City to respect local market realities\n",
    "df = df.groupby('city', group_keys=False).apply(remove_outliers_iqr)\n",
    "print(f\"Entries after IQR cleaning: {len(df)}\")\n",
    "\n",
    "sns.boxplot(data=df, x='city', y='price_per_m2')\n",
    "plt.title(\"Price per m² Distribution after Outlier Removal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acca92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['region'].unique()\n",
    "# df['region'] = df['region'].replace('Ariana', 'Ariana Ville')\n",
    "# df['region'] = df['region'].replace('La Manouba', 'Manouba Ville')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2066c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_region_names(df, region_column='region'):\n",
    "    \"\"\"\n",
    "    Cleans and merges duplicate region names in the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        The input dataset\n",
    "    region_column : str\n",
    "        The name of the column containing region names (default: 'region')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        Dataset with standardized region names (all columns preserved)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define grouped regions (first item in each list is the canonical name)\n",
    "    grouped_regions = [\n",
    "        [\"Ariana Ville\"],\n",
    "        [\"Jardins D'el Menzah\", \"Jardins El Menzah\"],\n",
    "        [\"Ennasr\"],\n",
    "        [\"Autres villes\"],\n",
    "        [\"Borj Louzir\"],\n",
    "        [\"La Soukra\"],\n",
    "        [\"Ghazela\"],\n",
    "        [\"Ariana\"],\n",
    "        [\"Chotrana\"],\n",
    "        [\"Raoued\"],\n",
    "        [\"Mnihla\"],\n",
    "        [\"Ettadhamen\"],\n",
    "        [\"Sidi Thabet\"],\n",
    "        [\"Fouchana\"],\n",
    "        [\"Mornag\"],\n",
    "        [\"Medina Jedida\"],\n",
    "        [\"El Mourouj\"],\n",
    "        [\"Hammam Chott\"],\n",
    "        [\"Ezzahra\"],\n",
    "        [\"Boumhel\"],\n",
    "        [\"Hammam Lif\"],\n",
    "        [\"Radès\", \"Rads\"],\n",
    "        [\"Mégrine\", \"Mgrine\"],\n",
    "        [\"Ben arous\", \"Ben Arous\"],\n",
    "        [\"Manouba Ville\"],\n",
    "        [\"Oued Ellil\"],\n",
    "        [\"Denden\"],\n",
    "        [\"La manouba\", \"La Manouba\"],\n",
    "        [\"Douar Hicher\"],\n",
    "        [\"Le Bardo\"],\n",
    "        [\"L'aouina\", \"L Aouina\"],\n",
    "        [\"La Marsa\"],\n",
    "        [\"La Goulette\"],\n",
    "        [\"Carthage\"],\n",
    "        [\"Agba\"],\n",
    "        [\"Ettahrir\"],\n",
    "        [\"Menzah\"],\n",
    "        [\"Tunis\"],\n",
    "        [\"Sidi Daoud\"],\n",
    "        [\"Le Kram\"],\n",
    "        [\"El Kabaria\"],\n",
    "        [\"El Ouardia\"],\n",
    "        [\"Manar\"],\n",
    "        [\"Ezzouhour\"],\n",
    "        [\"Centre Urbain Nord\"],\n",
    "        [\"Médina\"],\n",
    "        [\"Centre Ville - Lafayette\", \"Centre Ville Lafayette\"],\n",
    "        [\"Sidi Bou Said\"],\n",
    "        [\"Hraïria\", \"Hraria\"],\n",
    "        [\"Sidi Hassine\"],\n",
    "        [\"Mutuelleville\"],\n",
    "        [\"Ain Zaghouan Nord\"],\n",
    "        [\"Chotrana 1\"],\n",
    "        [\"Cit Ennasr 2\"],\n",
    "        [\"Bab Souika\"],\n",
    "        [\"Borj Cedria\"],\n",
    "        [\"El Mourouj 5\"],\n",
    "        [\"El Menzah 7\"],\n",
    "        [\"Jardins De Carthage\"],\n",
    "        [\"El Omrane Suprieur\"],\n",
    "        [\"Ain Zaghouen\", \"Ain Zaghouan\"],\n",
    "        [\"El Mourouj 6\"],\n",
    "        [\"El Mourouj 1\"],\n",
    "        [\"El Manar 1\"],\n",
    "        [\"Riadh Andalous\"],\n",
    "        [\"El Menzah 9\"],\n",
    "        [\"Ariana Essoughra\"],\n",
    "        [\"Cit Olympique\"],\n",
    "        [\"El Menzah 4\"],\n",
    "        [\"Les Jardins El_Menzah_2\"],\n",
    "        [\"Montplaisir\"],\n",
    "        [\"Dar Fadhal\"],\n",
    "        [\"El Menzah 5\"],\n",
    "        [\"Mohamedia\"],\n",
    "        [\"El Manar 2\"],\n",
    "        [\"Cit El Khadra\"],\n",
    "        [\"Cite Ennkhilet\"],\n",
    "        [\"Ain Zaghouan Sud\"],\n",
    "        [\"Tunis Belvedere\"],\n",
    "        [\"Gammarth\"],\n",
    "        [\"Lac 2\"],\n",
    "        [\"Ksar Said\"],\n",
    "        [\"Cit Hedi Nouira\"],\n",
    "        [\"El Menzah 6\"],\n",
    "        [\"Les Jardins El_Menzah_1\"],\n",
    "        [\"Lac 1\"],\n",
    "        [\"El Mourouj 4\"]\n",
    "    ]\n",
    "    \n",
    "    # Create mapping dictionary (all variants map to the first item in each group)\n",
    "    region_mapping = {}\n",
    "    for group in grouped_regions:\n",
    "        canonical_name = group[0]  # First name is the standard\n",
    "        for variant in group:\n",
    "            region_mapping[variant] = canonical_name\n",
    "    \n",
    "    # Create a copy of the entire dataframe to avoid modifying the original\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    # Apply the mapping ONLY to the region column\n",
    "    df_cleaned[region_column] = df_cleaned[region_column].replace(region_mapping)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "df_cleaned = clean_region_names(df, region_column='region')\n",
    "df = df_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973771f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_region_cleaning(df_original, df_cleaned, region_column='region'):\n",
    "    \"\"\"\n",
    "    Tests whether the region cleaning function worked correctly.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df_original : pandas.DataFrame\n",
    "        The original dataset before cleaning\n",
    "    df_cleaned : pandas.DataFrame\n",
    "        The cleaned dataset after cleaning\n",
    "    region_column : str\n",
    "        The name of the column containing region names\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : True if all tests passed, False otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    # Test 1: Check if dataframe shapes are the same\n",
    "    if df_original.shape != df_cleaned.shape:\n",
    "        print(f\"❌ FAILED: Shape changed from {df_original.shape} to {df_cleaned.shape}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 2: Check if duplicates were merged (unique regions should be less or equal)\n",
    "    original_unique = df_original[region_column].nunique()\n",
    "    cleaned_unique = df_cleaned[region_column].nunique()\n",
    "    \n",
    "    if cleaned_unique > original_unique:\n",
    "        print(f\"❌ FAILED: Unique regions increased from {original_unique} to {cleaned_unique}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 3: Check specific duplicate pairs were merged\n",
    "    duplicate_pairs = [\n",
    "        (\"Radès\", \"Rads\"),\n",
    "        (\"Mégrine\", \"Mgrine\"),\n",
    "        (\"Ben arous\", \"Ben Arous\"),\n",
    "        (\"La manouba\", \"La Manouba\"),\n",
    "        (\"L'aouina\", \"L Aouina\"),\n",
    "        (\"Jardins D'el Menzah\", \"Jardins El Menzah\"),\n",
    "        (\"Hraïria\", \"Hraria\"),\n",
    "        (\"Ain Zaghouen\", \"Ain Zaghouan\"),\n",
    "        (\"Centre Ville - Lafayette\", \"Centre Ville Lafayette\")\n",
    "    ]\n",
    "    \n",
    "    for pair in duplicate_pairs:\n",
    "        # Check if both variants existed in original\n",
    "        if all(variant in df_original[region_column].values for variant in pair):\n",
    "            # Check if both still exist in cleaned (they shouldn't)\n",
    "            if pair[0] in df_cleaned[region_column].values and pair[1] in df_cleaned[region_column].values:\n",
    "                print(f\"❌ FAILED: {pair[0]} and {pair[1]} were not merged\")\n",
    "                return False\n",
    "    \n",
    "    # Test 4: Check no rows were lost\n",
    "    if len(df_original) != len(df_cleaned):\n",
    "        print(f\"❌ FAILED: Rows changed from {len(df_original)} to {len(df_cleaned)}\")\n",
    "        return False\n",
    "    \n",
    "    # All tests passed\n",
    "    print(f\"✅ PASSED: Cleaning successful!\")\n",
    "    print(f\"   - Rows preserved: {len(df_cleaned)}\")\n",
    "    print(f\"   - Unique regions: {original_unique} → {cleaned_unique}\")\n",
    "    print(f\"   - Merged: {original_unique - cleaned_unique} duplicate regions\")\n",
    "    return True\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "# df_cleaned = clean_region_names(df, region_column='region')\n",
    "is_ok = test_region_cleaning(df, df_cleaned, region_column='region')\n",
    "# \n",
    "if is_ok:\n",
    "    print(\"Everything is OK!\")\n",
    "else:\n",
    "    print(\"Something went wrong!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
