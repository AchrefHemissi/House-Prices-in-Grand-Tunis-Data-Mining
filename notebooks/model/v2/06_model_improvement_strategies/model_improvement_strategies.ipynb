{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60cfe55a",
   "metadata": {},
   "source": [
    "## 6. Model Improvement Strategies\n",
    "\n",
    "**Approach to improve RÂ² and reduce errors:**\n",
    "1. **Weighted Voting**: Give less weight to RandomForest (overfits) and more to SVR/GradientBoosting\n",
    "2. **XGBoost**: More powerful gradient boosting with better regularization\n",
    "3. **Feature Engineering**: Add polynomial/interaction features\n",
    "4. **Hyperparameter Fine-Tuning**: Search deeper for optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6.1 Weighted Voting Ensemble (Reduce Overfitting) ---\n",
    "# Give less weight to RandomForest (overfits) and more to SVR/GradientBoosting\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"IMPROVEMENT 1: Weighted Voting Ensemble\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Re-create estimators for weighted voting\n",
    "weighted_estimators = []\n",
    "\n",
    "# SVR - Best balance\n",
    "svr_params = {k.replace('model__', ''): v for k, v in model_results['SVR']['Best_Params'].items()}\n",
    "svr_model = SVR(**svr_params)\n",
    "weighted_estimators.append(('SVR', svr_model))\n",
    "\n",
    "# GradientBoosting - Second best\n",
    "gb_params = {k.replace('model__', ''): v for k, v in model_results['GradientBoosting']['Best_Params'].items()}\n",
    "gb_model = GradientBoostingRegressor(**gb_params, random_state=42)\n",
    "weighted_estimators.append(('GradientBoosting', gb_model))\n",
    "\n",
    "# RandomForest - Third (but reduce weight due to overfitting)\n",
    "rf_params = {k.replace('model__', ''): v for k, v in model_results['RandomForest']['Best_Params'].items()}\n",
    "rf_model = RandomForestRegressor(**rf_params, random_state=42, n_jobs=-1)\n",
    "weighted_estimators.append(('RandomForest', rf_model))\n",
    "\n",
    "# Weights: SVR (high weight), GradientBoosting (high), RandomForest (low due to overfitting)\n",
    "weights = [0.4, 0.4, 0.2]\n",
    "\n",
    "weighted_voting_pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('voting', VotingRegressor(estimators=weighted_estimators, weights=weights))\n",
    "])\n",
    "\n",
    "print(f\"Weights: SVR={weights[0]}, GradientBoosting={weights[1]}, RandomForest={weights[2]}\")\n",
    "print(\"\\nTraining Weighted Voting Ensemble...\")\n",
    "weighted_voting_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_weighted = weighted_voting_pipeline.predict(X_test)\n",
    "r2_weighted = r2_score(y_test, y_pred_weighted)\n",
    "mae_weighted = mean_absolute_error(np.expm1(y_test), np.expm1(y_pred_weighted))\n",
    "rmse_weighted = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_weighted)))\n",
    "\n",
    "print(f\"\\nWeighted Voting Results:\")\n",
    "print(f\"  RÂ² Score: {r2_weighted:.4f} (was {r2_voting:.4f})\")\n",
    "print(f\"  MAE: {mae_weighted:,.0f} TND (was {mae_voting:,.0f})\")\n",
    "print(f\"  RMSE: {rmse_weighted:,.0f} TND (was {rmse_voting:,.0f})\")\n",
    "\n",
    "improvement_r2 = (r2_weighted - r2_voting) * 100\n",
    "print(f\"\\n  RÂ² Change: {improvement_r2:+.2f}%\")\n",
    "\n",
    "model_results['Weighted_Voting'] = {\n",
    "    'R2_Test': r2_weighted, 'MAE': mae_weighted, 'RMSE': rmse_weighted\n",
    "}\n",
    "best_estimators['Weighted_Voting'] = weighted_voting_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f5d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6.2 XGBoost with Regularization ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IMPROVEMENT 2: XGBoost with Strong Regularization\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    from xgboost import XGBRegressor\n",
    "    \n",
    "    # XGBoost with regularization to prevent overfitting\n",
    "    xgb_pipeline = Pipeline([\n",
    "        ('prep', preprocessor),\n",
    "        ('model', XGBRegressor(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=4,\n",
    "            min_child_weight=3,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            reg_alpha=0.1,  # L1 regularization\n",
    "            reg_lambda=1.0,  # L2 regularization\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # GridSearch for XGBoost\n",
    "    xgb_params = {\n",
    "        'model__max_depth': [3, 4, 5],\n",
    "        'model__learning_rate': [0.03, 0.05, 0.1],\n",
    "        'model__n_estimators': [150, 200, 300],\n",
    "        'model__reg_alpha': [0, 0.1, 0.5],\n",
    "        'model__reg_lambda': [0.5, 1.0, 2.0]\n",
    "    }\n",
    "    \n",
    "    print(\"Running GridSearch for XGBoost (this may take a few minutes)...\")\n",
    "    xgb_grid = GridSearchCV(xgb_pipeline, xgb_params, cv=5, scoring='r2', n_jobs=-1, return_train_score=True)\n",
    "    xgb_grid.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_xgb = xgb_grid.predict(X_test)\n",
    "    r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "    mae_xgb = mean_absolute_error(np.expm1(y_test), np.expm1(y_pred_xgb))\n",
    "    rmse_xgb = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_xgb)))\n",
    "    \n",
    "    # Bias-variance for XGBoost\n",
    "    xgb_cv_train = xgb_grid.cv_results_['mean_train_score'][xgb_grid.best_index_]\n",
    "    xgb_cv_test = xgb_grid.cv_results_['mean_test_score'][xgb_grid.best_index_]\n",
    "    \n",
    "    print(f\"\\nBest XGBoost Params: {xgb_grid.best_params_}\")\n",
    "    print(f\"\\nXGBoost Results:\")\n",
    "    print(f\"  RÂ² Score: {r2_xgb:.4f}\")\n",
    "    print(f\"  MAE: {mae_xgb:,.0f} TND\")\n",
    "    print(f\"  RMSE: {rmse_xgb:,.0f} TND\")\n",
    "    print(f\"  CV Train RÂ²: {xgb_cv_train:.4f} | CV Test RÂ²: {xgb_cv_test:.4f}\")\n",
    "    print(f\"  Variance Gap: {xgb_cv_train - xgb_cv_test:.4f}\")\n",
    "    \n",
    "    model_results['XGBoost'] = {\n",
    "        'R2_Test': r2_xgb, 'MAE': mae_xgb, 'RMSE': rmse_xgb,\n",
    "        'CV_Train_R2': xgb_cv_train, 'CV_Test_R2': xgb_cv_test,\n",
    "        'Variance_Indicator': xgb_cv_train - xgb_cv_test\n",
    "    }\n",
    "    best_estimators['XGBoost'] = xgb_grid.best_estimator_\n",
    "    XGB_AVAILABLE = True\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Install with: pip install xgboost\")\n",
    "    XGB_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d58949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6.3 Enhanced Feature Engineering ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IMPROVEMENT 3: Enhanced Feature Engineering\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Create interaction and polynomial features\n",
    "df_enhanced = df.copy()\n",
    "\n",
    "# New features\n",
    "df_enhanced['size_x_rooms'] = df_enhanced['size'] * df_enhanced['room_count']\n",
    "df_enhanced['luxury_score'] = (df_enhanced['size'] / 100) * (df_enhanced['bathroom_count'] + 1)\n",
    "df_enhanced['space_efficiency'] = df_enhanced['size'] / (df_enhanced['room_count'] + df_enhanced['bathroom_count'])\n",
    "\n",
    "# Updated features list\n",
    "enhanced_features = ['city', 'region', 'size', 'room_count', 'bathroom_count', \n",
    "                     'avg_room_size', 'size_x_rooms', 'luxury_score', 'space_efficiency']\n",
    "\n",
    "X_enhanced = df_enhanced[enhanced_features]\n",
    "y_enhanced = df_enhanced['log_price']\n",
    "\n",
    "# Updated preprocessing\n",
    "enhanced_numeric = ['size', 'room_count', 'bathroom_count', \n",
    "                    'avg_room_size', 'size_x_rooms', 'luxury_score', 'space_efficiency']\n",
    "\n",
    "enhanced_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', RobustScaler(), enhanced_numeric),\n",
    "        ('cat', OneHotEncoder(drop='first'), ['city', 'region'])\n",
    "    ])\n",
    "\n",
    "X_train_enh, X_test_enh, y_train_enh, y_test_enh = train_test_split(\n",
    "    X_enhanced, y_enhanced, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"New features added: size_x_rooms, luxury_score, space_efficiency\")\n",
    "print(f\"Total features: {len(enhanced_features)}\")\n",
    "\n",
    "# Train GradientBoosting with enhanced features\n",
    "enhanced_gb_pipeline = Pipeline([\n",
    "    ('prep', enhanced_preprocessor),\n",
    "    ('model', GradientBoostingRegressor(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=5,\n",
    "        min_samples_split=5,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "enhanced_gb_pipeline.fit(X_train_enh, y_train_enh)\n",
    "y_pred_enh = enhanced_gb_pipeline.predict(X_test_enh)\n",
    "\n",
    "r2_enh = r2_score(y_test_enh, y_pred_enh)\n",
    "mae_enh = mean_absolute_error(np.expm1(y_test_enh), np.expm1(y_pred_enh))\n",
    "rmse_enh = np.sqrt(mean_squared_error(np.expm1(y_test_enh), np.expm1(y_pred_enh)))\n",
    "\n",
    "print(f\"\\nEnhanced GradientBoosting Results:\")\n",
    "print(f\"  RÂ² Score: {r2_enh:.4f} (was {model_results['GradientBoosting']['R2_Test']:.4f})\")\n",
    "print(f\"  MAE: {mae_enh:,.0f} TND\")\n",
    "print(f\"  RMSE: {rmse_enh:,.0f} TND\")\n",
    "\n",
    "model_results['Enhanced_GB'] = {'R2_Test': r2_enh, 'MAE': mae_enh, 'RMSE': rmse_enh}\n",
    "best_estimators['Enhanced_GB'] = enhanced_gb_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0101bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6.4 Ultimate Ensemble: Best Models Combined ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IMPROVEMENT 4: Ultimate Weighted Ensemble\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Combine the best performers with optimal weights\n",
    "# Based on bias-variance analysis: favor low-variance models\n",
    "\n",
    "ultimate_estimators = []\n",
    "\n",
    "# SVR - Excellent balance\n",
    "svr_params = {k.replace('model__', ''): v for k, v in model_results['SVR']['Best_Params'].items()}\n",
    "svr_model = SVR(**svr_params)\n",
    "ultimate_estimators.append(('SVR', svr_model))\n",
    "\n",
    "# GradientBoosting - Good balance\n",
    "gb_params = {k.replace('model__', ''): v for k, v in model_results['GradientBoosting']['Best_Params'].items()}\n",
    "gb_model = GradientBoostingRegressor(**gb_params, random_state=42)\n",
    "ultimate_estimators.append(('GradientBoosting', gb_model))\n",
    "\n",
    "# AdaBoost - Moderate variance\n",
    "ada_params = {k.replace('model__', ''): v for k, v in model_results['AdaBoost']['Best_Params'].items()}\n",
    "ada_model = AdaBoostRegressor(**ada_params, random_state=42)\n",
    "ultimate_estimators.append(('AdaBoost', ada_model))\n",
    "\n",
    "# Ridge - Very stable (low variance anchor)\n",
    "ridge_params = {k.replace('model__', ''): v for k, v in model_results['Ridge']['Best_Params'].items()}\n",
    "ridge_model = Ridge(**ridge_params)\n",
    "ultimate_estimators.append(('Ridge', ridge_model))\n",
    "\n",
    "# Optimal weights based on variance indicators\n",
    "# SVR: 0.044 variance, GB: 0.050, AdaBoost: 0.043, Ridge: 0.013\n",
    "# Higher weight to lower variance models\n",
    "ultimate_weights = [0.35, 0.30, 0.20, 0.15]\n",
    "\n",
    "ultimate_pipeline = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('voting', VotingRegressor(estimators=ultimate_estimators, weights=ultimate_weights))\n",
    "])\n",
    "\n",
    "print(f\"Estimators: SVR, GradientBoosting, AdaBoost, Ridge\")\n",
    "print(f\"Weights: {dict(zip(['SVR', 'GB', 'AdaBoost', 'Ridge'], ultimate_weights))}\")\n",
    "print(\"\\nTraining Ultimate Ensemble...\")\n",
    "ultimate_pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred_ultimate = ultimate_pipeline.predict(X_test)\n",
    "r2_ultimate = r2_score(y_test, y_pred_ultimate)\n",
    "mae_ultimate = mean_absolute_error(np.expm1(y_test), np.expm1(y_pred_ultimate))\n",
    "rmse_ultimate = np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred_ultimate)))\n",
    "\n",
    "print(f\"\\nUltimate Ensemble Results:\")\n",
    "print(f\"  RÂ² Score: {r2_ultimate:.4f}\")\n",
    "print(f\"  MAE: {mae_ultimate:,.0f} TND\")\n",
    "print(f\"  RMSE: {rmse_ultimate:,.0f} TND\")\n",
    "\n",
    "model_results['Ultimate_Ensemble'] = {'R2_Test': r2_ultimate, 'MAE': mae_ultimate, 'RMSE': rmse_ultimate}\n",
    "best_estimators['Ultimate_Ensemble'] = ultimate_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36be3e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6.5 Final Improvement Comparison ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL IMPROVEMENT COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Collect all results\n",
    "improvement_results = {}\n",
    "for name in ['Voting_Ensemble', 'Weighted_Voting', 'Ultimate_Ensemble', 'Enhanced_GB']:\n",
    "    if name in model_results:\n",
    "        improvement_results[name] = {\n",
    "            'R2_Test': model_results[name]['R2_Test'],\n",
    "            'MAE': model_results[name]['MAE'],\n",
    "            'RMSE': model_results[name]['RMSE']\n",
    "        }\n",
    "\n",
    "if 'XGBoost' in model_results:\n",
    "    improvement_results['XGBoost'] = {\n",
    "        'R2_Test': model_results['XGBoost']['R2_Test'],\n",
    "        'MAE': model_results['XGBoost']['MAE'],\n",
    "        'RMSE': model_results['XGBoost']['RMSE']\n",
    "    }\n",
    "\n",
    "improvement_df = pd.DataFrame(improvement_results).T\n",
    "improvement_df = improvement_df.sort_values('R2_Test', ascending=False)\n",
    "\n",
    "print(improvement_df.round(4).to_string())\n",
    "\n",
    "# Best improved model\n",
    "best_improved_name = improvement_df['R2_Test'].idxmax()\n",
    "best_improved_r2 = improvement_df.loc[best_improved_name, 'R2_Test']\n",
    "original_best_r2 = r2_voting\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ðŸš€ BEST IMPROVED MODEL: {best_improved_name}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"   RÂ² Score: {best_improved_r2:.4f}\")\n",
    "print(f\"   Original Best (Voting): {original_best_r2:.4f}\")\n",
    "print(f\"   Improvement: {(best_improved_r2 - original_best_r2)*100:+.2f}%\")\n",
    "\n",
    "# Visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RÂ² Comparison\n",
    "ax1 = axes[0]\n",
    "all_r2 = {'Original_Voting (V1)': original_best_r2}\n",
    "for name in improvement_df.index:\n",
    "    all_r2[f'{name}'] = improvement_df.loc[name, 'R2_Test']\n",
    "    \n",
    "sorted_models = sorted(all_r2.items(), key=lambda x: x[1])\n",
    "names, values = zip(*sorted_models)\n",
    "colors = ['gold' if v == max(values) else ('green' if 'V1' in n else 'steelblue') for n, v in sorted_models]\n",
    "ax1.barh(names, values, color=colors)\n",
    "ax1.axvline(x=original_best_r2, color='red', linestyle='--', alpha=0.7, label=f'V1 Baseline: {original_best_r2:.4f}')\n",
    "ax1.set_xlabel('RÂ² Score')\n",
    "ax1.set_title('Improvement Comparison: RÂ² Score')\n",
    "ax1.legend()\n",
    "\n",
    "# MAE Comparison\n",
    "ax2 = axes[1]\n",
    "ax2.barh(improvement_df.index, improvement_df['MAE'], color=colors)\n",
    "ax2.set_xlabel('MAE (TND)')\n",
    "ax2.set_title('Improvement Comparison: Mean Absolute Error')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a807340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6.6 Select Final Champion and Validate ---\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL CHAMPION MODEL SELECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Select the best model overall (including improvements)\n",
    "all_models_df = pd.DataFrame(model_results).T\n",
    "all_models_df = all_models_df[['R2_Test', 'MAE', 'RMSE']].dropna()\n",
    "for col in ['R2_Test', 'MAE', 'RMSE']:\n",
    "    all_models_df[col] = pd.to_numeric(all_models_df[col], errors='coerce')\n",
    "all_models_df = all_models_df.sort_values('R2_Test', ascending=False)\n",
    "\n",
    "print(\"ALL MODELS FINAL RANKING:\")\n",
    "print(all_models_df.round(4).to_string())\n",
    "\n",
    "# Update best model\n",
    "best_model_name = all_models_df['R2_Test'].idxmax()\n",
    "best_model = best_estimators[best_model_name]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ðŸ† FINAL CHAMPION: {best_model_name}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"   RÂ² Score: {all_models_df.loc[best_model_name, 'R2_Test']:.4f}\")\n",
    "print(f\"   MAE: {all_models_df.loc[best_model_name, 'MAE']:,.0f} TND\")\n",
    "print(f\"   RMSE: {all_models_df.loc[best_model_name, 'RMSE']:,.0f} TND\")\n",
    "\n",
    "# Final residual check\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "y_test_final_real = np.expm1(y_test)\n",
    "y_pred_final_real = np.expm1(y_pred_final)\n",
    "final_residuals = y_test_final_real - y_pred_final_real\n",
    "\n",
    "print(f\"\\nðŸ“Š Final Residual Analysis:\")\n",
    "print(f\"   Mean Error: {final_residuals.mean():,.0f} TND (closer to 0 = low bias)\")\n",
    "print(f\"   Std Error: {final_residuals.std():,.0f} TND (lower = more consistent)\")\n",
    "print(f\"   Median Error: {final_residuals.median():,.0f} TND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f495736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6.7 Dynamic Conclusion: Why Improvements Didn't Beat Original ---\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def generate_improvement_conclusion(model_results):\n",
    "    \"\"\"Generate dynamic conclusion about improvement attempts\"\"\"\n",
    "    \n",
    "    baseline_r2 = model_results.get('Voting_Ensemble', {}).get('R2_Test', 0)\n",
    "    \n",
    "    # Models to compare\n",
    "    comparison_models = {\n",
    "        'XGBoost': 'Advanced regularization with GridSearch',\n",
    "        'Enhanced_GB': 'Added engineered features',\n",
    "        'Ultimate_Ensemble': 'Combined multiple models with weighting',\n",
    "        'Weighted_Voting': 'Adjusted ensemble weights',\n",
    "        'Elite_Ensemble': 'Selected only best models'\n",
    "    }\n",
    "    \n",
    "    md_content = \"### 6.7 Conclusion: Improvement Analysis\\n\\n\"\n",
    "    md_content += f\"**Baseline: Original Voting Ensemble (RÂ² = {baseline_r2:.4f}, MAE = {mae_voting:,.0f} TND)**\\n\\n\"\n",
    "    \n",
    "    # Build comparison table\n",
    "    md_content += \"| Attempted Improvement | RÂ² Score | Change | Why It Performed This Way |\\n\"\n",
    "    md_content += \"|----------------------|----------|--------|---------------------------|\\n\"\n",
    "    \n",
    "    improvements = []\n",
    "    for model_name, description in comparison_models.items():\n",
    "        if model_name in model_results:\n",
    "            r2 = model_results[model_name].get('R2_Test', 0)\n",
    "            change = r2 - baseline_r2\n",
    "            change_pct = change * 100\n",
    "            \n",
    "            # Determine reason\n",
    "            if model_name == 'XGBoost':\n",
    "                r2_train = model_results[model_name].get('R2_Train', 0)\n",
    "                var_gap = r2_train - r2\n",
    "                reason = f\"Variance gap {var_gap:.3f} indicates {'overfitting' if var_gap > 0.05 else 'good fit'}\"\n",
    "            elif model_name == 'Enhanced_GB':\n",
    "                reason = \"New features introduced noise without proper validation\" if change < 0 else \"Feature engineering helped\"\n",
    "            elif 'Ensemble' in model_name:\n",
    "                reason = \"Ensemble composition matters - mixing weak learners can reduce performance\" if change < 0 else \"Better model combination\"\n",
    "            else:\n",
    "                reason = \"Different model characteristics\"\n",
    "            \n",
    "            symbol = \"âœ…\" if change >= 0 else \"âŒ\"\n",
    "            md_content += f\"| {model_name} {symbol} | {r2:.4f} | {change_pct:+.2f}% | {reason} |\\n\"\n",
    "            improvements.append((model_name, r2, change))\n",
    "    \n",
    "    md_content += \"\\n**What This Tells Us:**\\n\\n\"\n",
    "    \n",
    "    best_attempt = max(improvements, key=lambda x: x[1]) if improvements else None\n",
    "    if best_attempt and best_attempt[1] >= baseline_r2:\n",
    "        md_content += f\"âœ… **{best_attempt[0]}** achieved the best performance (RÂ² = {best_attempt[1]:.4f})\\n\\n\"\n",
    "    else:\n",
    "        md_content += f\"âœ… **The Original Voting Ensemble remains optimal** (RÂ² = {baseline_r2:.4f})\\n\\n\"\n",
    "    \n",
    "    # Calculate average variance gap for ensemble\n",
    "    ensemble_variance = []\n",
    "    for model in ['SVR', 'GradientBoosting', 'RandomForest']:\n",
    "        if model in model_results:\n",
    "            r2_train = model_results[model].get('R2_Train', 0)\n",
    "            r2_test = model_results[model].get('R2_Test', 0)\n",
    "            ensemble_variance.append(r2_train - r2_test)\n",
    "    \n",
    "    if ensemble_variance:\n",
    "        avg_var_gap = sum(ensemble_variance) / len(ensemble_variance)\n",
    "        md_content += f\"- Ensemble averaging successfully reduces overfitting (avg variance gap: {avg_var_gap:.3f})\\n\"\n",
    "    \n",
    "    md_content += f\"- Model explains {baseline_r2*100:.1f}% of price variance - strong for real estate with limited features\\n\"\n",
    "    md_content += \"- Further improvements require: more data, external features, or domain-specific engineering\\n\"\n",
    "    \n",
    "    return md_content\n",
    "\n",
    "# Generate and display\n",
    "display(Markdown(generate_improvement_conclusion(model_results)))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
